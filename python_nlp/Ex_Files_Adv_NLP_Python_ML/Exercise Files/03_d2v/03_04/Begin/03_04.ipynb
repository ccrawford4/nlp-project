{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec: How To Prep Document Vectors For Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data, clean it, split it into train/test, and then train a doc2vec model\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('../../../data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2)\n",
    "\n",
    "tagged_docs_tr = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train)]\n",
    "\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs_tr,\n",
    "                                  vector_size=50,\n",
    "                                  window=2,\n",
    "                                  min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.6718694e-05, -6.1018830e-03, -1.6303412e-03, -1.5231987e-02,\n",
       "       -1.6462184e-02, -1.6894735e-02,  1.8227153e-02,  3.5228401e-02,\n",
       "       -2.8235016e-02, -2.6804281e-02,  4.7515244e-03, -3.6090210e-02,\n",
       "       -5.0572259e-03,  4.9486913e-04, -3.1516191e-02,  1.1341713e-02,\n",
       "        3.4319617e-02,  8.4469747e-03, -3.1408001e-02, -3.3346064e-02,\n",
       "        1.0574155e-02,  1.2045715e-02,  5.0422393e-02, -1.6883573e-02,\n",
       "        3.1222956e-02,  1.1067304e-02, -6.2591676e-03,  7.4057304e-03,\n",
       "       -2.8276602e-02,  1.4740040e-02,  2.4008411e-03,  9.2667417e-04,\n",
       "        1.2350962e-02,  6.6436367e-04, -2.1950267e-02,  1.7671494e-02,\n",
       "        5.1144976e-03,  5.7360362e-03,  1.9055061e-03, -1.0085327e-02,\n",
       "        2.5385160e-02, -6.5294304e-03, -1.8226573e-02, -7.9131703e-04,\n",
       "        4.8835255e-02, -9.8452764e-03, -3.3947208e-04, -1.1744170e-02,\n",
       "        1.0085868e-02,  2.8494980e-02], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does a document vector look like again?\n",
    "d2v_model.infer_vector(['convert', 'words', 'to', 'vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we prepare these vectors to be used in a machine learning model?\n",
    "vectors = [[d2v_model.infer_vector(words)] for words in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.2833733e-02, -2.3581032e-02, -1.3104286e-02, -1.2162490e-02,\n",
       "         1.2179788e-02, -1.0820004e-02,  3.5086337e-02,  4.2638820e-02,\n",
       "        -5.0329126e-02, -1.6652919e-02,  1.4888411e-04, -1.8659070e-02,\n",
       "        -1.6654829e-02,  4.3615862e-03, -2.0526927e-02,  2.1895096e-03,\n",
       "         2.9594881e-02,  1.4362046e-02, -2.6405234e-02, -2.4092495e-02,\n",
       "         9.2293723e-03,  1.5093700e-03,  5.9560612e-02, -1.1563199e-02,\n",
       "         1.7908353e-02,  1.0593006e-02, -5.2540218e-03,  5.9740008e-03,\n",
       "        -1.2158540e-02,  7.9866508e-03, -2.1727607e-04, -6.2691385e-04,\n",
       "        -1.2695984e-02,  8.2732895e-03,  9.1476431e-05,  8.4015913e-03,\n",
       "         1.2128290e-02,  8.7802317e-03,  2.0240773e-02, -1.6412701e-02,\n",
       "         2.9382497e-02, -1.5369654e-04, -1.4008183e-02,  8.9987386e-03,\n",
       "         2.1246713e-02, -1.5917656e-04, -1.9540476e-02, -1.5193766e-02,\n",
       "         8.7318625e-03,  2.0459848e-02], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w2v vector needs arrays not lists to create element-wise averaging (easier w/array)\n",
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
